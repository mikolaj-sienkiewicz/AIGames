{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from GridEnv import GridWorld\n",
    "from Agent import NeuralQLearningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_rewards(rewards):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(rewards)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    \n",
    "def run_agent_in_env(env, agent, episodes, learning=False, plot=False, render=False, plot_interval=1000):\n",
    "    rewards = []\n",
    "    for episode in range(episodes):\n",
    "#         if episode%10000==0:\n",
    "#             env.render()\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done :\n",
    "            if render:\n",
    "                env.render()\n",
    "            # Zapytajmy agenta o akcje dla aktualnego stanu\n",
    "            #print(observation)\n",
    "            action = agent.get_action(observation, learning)\n",
    "            \n",
    "            # Wykonajmy akcje\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            #print(reward)\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Jeśli się uczymy, przekażmy przejście do agenta\n",
    "            if learning:\n",
    "                agent.process_transition(observation, action, reward, next_observation, done)\n",
    "            \n",
    "            observation = next_observation\n",
    "        rewards.append(total_reward)\n",
    "        \n",
    "        # Wyświetl na wykresie nagrody otrzymane po kolei w epizodach\n",
    "        if plot and episode % plot_interval == 0:\n",
    "            plot_rewards(rewards)\n",
    "    return rewards    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorld(9, 9, _) #gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/mikol/Desktop/Sem10/AI_in_games/Agent.py:100: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "agent = NeuralQLearningAgent(env,0.99,1,0.0001,[81],batch_size=64,n_actions=4,update_every=20,\n",
    "                             useReplay_mem=True,useNetwork_freezing=True,useDouble_Qlearning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewards = run_agent_in_env(env, agent, 100, learning=True, plot=True, plot_interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL TO FILE\n",
    "T.save(agent.q_eval, \"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE MODEL FROM FILE\n",
    "model=T.load(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/mikol/Desktop/Sem10/AI_in_games/Agent.py:100: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "agent = NeuralQLearningAgent(env,0.99,1,0.0001,[81],batch_size=64,n_actions=4,update_every=20,\n",
    "                             useReplay_mem=True,useNetwork_freezing=True,useDouble_Qlearning=True,q_eval=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "X\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\tX\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\tX\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\tX\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\tX\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\tX\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\tX\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\tX\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\tX\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\tX\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\tX\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\tX\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\tX\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\tX\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\tX\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\tX\t\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t\n",
      "\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/mikol/Desktop/Sem10/AI_in_games/Agent.py:187: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  state = T.tensor([observation]).to(self.q_eval.device)\n"
     ]
    }
   ],
   "source": [
    "rewards = run_agent_in_env(env, agent, 1, learning=False, plot=False, render=True, plot_interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
